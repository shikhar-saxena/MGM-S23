---
title: Class 9
date: February 16, 2023
---

# Recap

\begin{align*}
  D_f(p\| q) &= \int q(x) \sup_t \bc{ t \frac{p(x)}{q(x)} - f^*(t)} dx\\
  &= \sup_t \int q(x) \bc{ T_1(x) \frac{p(x)}{q(x)} - f^*(T_1(x))}\\
  &\ge \int q(x) T_1(x) \frac{p(x)}{q(x)} - f^*(T_1(x))
\end{align*}

$$
\therefore D_f(p\| q) = \sup_{T:X\ra \mathbb{R}} \int_X \bp{T(x) p(x) - f^*(T(x)) q(x)} dx
$$ 

Using parameterized family of function $T_\phi$ to approximate the optimal function $T$, can minimize an f-divergence between $p$ and $p_\theta$ (**GAN problem**) 

\begin{align*}
\theta_s &= arg\ \min_\theta \sup_\phi \bs{ E_{x\sim p} T_\phi(x) - E_{x\sim p_\theta} f^*(T_\phi(x)) }\\
&= arg\ \min_\theta \sup_\phi \bs{ E_{x\sim p} T_\phi(x) - E f^*(T_\phi(g_\theta(z))) } 
\end{align*}

where $z \ra g_\theta(z) = x$

In 2014 paper, *I. Goodfellow et al, Generative Adversarial Networks*

\underline{Parameterizing:} $T_\phi(x) = \log (d_\phi(x))$

$$
\theta_f= arg\ \min_\theta \sup_\phi \bs{ E_{x\sim p} \log(d_\phi(x)) + E_{z\sim q}\log(1 - d_\phi(g_\theta(z))) } 
$$

# Algorithm for GAN

\begin{algorithm}
  \For{training iterations}{
    \For{$k$ steps}{
      Sample minibatch of $m$ noise sample $\{z^1, z^2, \ldots, z^m\}$ from priors $p_g(z)$

      Sample minibatch of $m$ examples $\{x^{(1)}, x^{(2)}, \ldots, x^{(m)}\}$ from data generating distribution $p_{data}(x)$ 
      
      Update the discriminator by ascending its stochastic gradient

      $$
      u^i \la \nabla_\phi \bp{ 1/m \sum_{i=1}^m \log d_\phi (x^i) + \log(1 - d_\phi(g_\theta(z^i)))} \quad (\phi^{i+1} \la \phi^i + \eta u^i)$$
    }

    Sample minibatch of $m$ noise samples $\{z^1, \ldots , z^m\}$
    
    Update the generator by descending 

    $$v_i = \nabla_\theta 1/m \log(1 - d_\phi (g_\theta (z^i)))\quad (\theta^{i+1} \la \theta^i - \eta v^i) $$

  }
  \caption{GAN}
\end{algorithm}


\begin{prop}
  For $G$ fixed, optimal discriminator $D$ is
  $$
  D_G^*(x) = \frac{p_{data} (x)}{p_{data}(x) + p_g(x)}
  $$ 
\end{prop}

\begin{proof}
  Recall for Two-player game
  
  $$
  \min_G \max_D V(D,G) = E_{x\sim p_{data}(x)} \log D(x) + E_{z\sim p_Z(z)} \bs{\log (1 - D(G(z)))}
  $$ 

  Therefore, for a given $G$, discriminator $D$ wants to maximize $V(G,D)$ 

  $$
  V(G,D) = \int_x p_{data}(x) \log(D(x)) dx + p_g (x) \log(1 - D(x)) dx
  $$ 

  For any $(a,b) \in \mathbb{R}^2$ the function $f(y): y \ra a \log y + b \log (1 - y)$ achieves max in $[0,1]$ at $\frac{a }{a+b }$.

  $f'(y) = \frac{a }{y} + \frac{b (-1)}{1 - y} = 0 \implies y = \frac{a }{a + b}$

  Minimize game become


\end{proof}
